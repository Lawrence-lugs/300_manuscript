@article{Ali_2022,
  title    = {Harris Hawks Sparse Auto-Encoder Networks for Automatic Speech Recognition System},
  year     = {2022},
  author   = {Mohammed Hasan Ali and Mustafa Musa and Mustafa Musa Jaber and Sura Khalil Abd and Amjad Rehman and Tanzila Saba and Mazhar Javed Awan and Robertas Damasevicius and Saeed Ali Bahaj},
  doi      = {10.3390/app12031091},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {4206517883},
  journal  = {Applied Sciences},
  abstract = {Automatic speech recognition (ASR) is an effective technique that can convert human speech into text format or computer actions. ASR systems are widely used in smart appliances, smart homes, and biometric systems. Signal processing and machine learning techniques are incorporated to recognize speech. However, traditional systems have low performance due to a noisy environment. In addition to this, accents and local differences negatively affect the ASR system’s performance while analyzing speech signals. A precise speech recognition system was developed to improve the system performance to overcome these issues. This paper uses speech information from jim-schwoebel voice datasets processed by Mel-frequency cepstral coefficients (MFCCs). The MFCC algorithm extracts the valuable features that are used to recognize speech. Here, a sparse auto-encoder (SAE) neural network is used to classify the model, and the hidden Markov model (HMM) is used to decide on the speech recognition. The network performance is optimized by applying the Harris Hawks optimization (HHO) algorithm to fine-tune the network parameter. The fine-tuned network can effectively recognize speech in a noisy environment.}
}
@article{alibart2012high,
  title     = {High precision tuning of state for memristive devices by adaptable variation-tolerant algorithm},
  author    = {Alibart, Fabien and Gao, Ligang and Hoskins, Brian D and Strukov, Dmitri B},
  journal   = {Nanotechnology},
  volume    = {23},
  number    = {7},
  pages     = {075201},
  year      = {2012},
  publisher = {IOP Publishing}
}
@misc{allinger2017magnetic,
  title     = {Magnetic shielding of perpendicular STT-MRAM},
  author    = {Allinger, Robert and Hofmann, Karl and Knobloch, Klaus and Strenz, Robert},
  year      = {2017},
  month     = feb # {~7},
  publisher = {Google Patents},
  note      = {US Patent 9,564,403}
}
@article{alsheikh2014machine,
  title    = {Machine Learning in Wireless Sensor Networks: Algorithms, Strategies, and Applications},
  year     = {2014},
  author   = {Mohammad Abu Alsheikh and Shaowei Lin and Dusit Niyato and Hwee-Pink Tan},
  doi      = {10.1109/comst.2014.2320099},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {2128569883},
  journal  = {IEEE Communications Surveys and Tutorials},
  abstract = {Wireless sensor networks (WSNs) monitor dynamic environments that change rapidly over time. This dynamic behavior is either caused by external factors or initiated by the system designers themselves. To adapt to such conditions, sensor networks often adopt machine learning techniques to eliminate the need for unnecessary redesign. Machine learning also inspires many practical solutions that maximize resource utilization and prolong the lifespan of the network. In this paper, we present an extensive literature review over the period 2002–2013 of machine learning methods that were used to address common issues in WSNs. The advantages and disadvantages of each proposed algorithm are evaluated against the corresponding problem. We also provide a comparative guide to aid WSN designers in developing suitable machine learning solutions for their specific application challenges.}
}

@inproceedings{antonio2017implementation,
  title        = {Implementation of dynamic voltage frequency scaling on a processor for wireless sensing applications},
  author       = {Antonio, Ryan Albert and de la Costa, Rafael Mari and Ison, Aldrin Rolf and Lim, Wesley Kaiser and Pajado, Robert Adrian and Roque, Deanne Bianca and Yutuc, Ruelle and Densing, Chris Vincent and de Leon, Maria Theresa and Rosales, Marc and others},
  booktitle    = {TENCON 2017-2017 IEEE Region 10 Conference},
  pages        = {2955--2960},
  year         = {2017},
  organization = {IEEE}
}
@article{article_key,
  address   = {City},
  publisher = {Publisher},
  author    = {Smith, James},
  title     = {Article title},
  year      = {2013},
  volume    = {14},
  number    = {6},
  pages     = {1--8},
  month     = {March}
}
@article{Banbury_2021,
  title    = {MLPerf Tiny Benchmark},
  year     = {2021},
  author   = {C. Banbury and V. Reddi and P. Torelli and J. Holleman and Nat Jeffries and C. Király and Pietro Montino and David Kanter and Sebastian Ahmed and Danilo Pau and Urmish Thakker and Antonio Torrini and P. Warden and Jay Cordaro and G. D. Guglielmo and Javier Mauricio Duarte and Stephen Gibellini and Videet Parekh and Honson Tran and Nhan Tran and Niu Wenxu and Xu Xuesong},
  doi      = {null},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {null},
  journal  = {NeurIPS Datasets and Benchmarks},
  abstract = {Advancements in ultra-low-power tiny machine learning (TinyML) systems promise to unlock an entirely new class of smart applications. However, continued progress is limited by the lack of a widely accepted and easily reproducible benchmark for these systems. To meet this need, we present MLPerf Tiny, the ﬁrst industry-standard benchmark suite for ultra-low-power tiny machine learning systems. The benchmark suite is the collaborative effort of more than 50 organizations from industry and academia and reﬂects the needs of the community. MLPerf Tiny measures the accuracy, latency, and energy of machine learning inference to properly evaluate the tradeoffs between systems. Additionally, MLPerf Tiny implements a modular design that enables benchmark submitters to show the beneﬁts of their product, regardless of where it falls on the ML deployment stack, in a fair and reproducible manner. The suite features four benchmarks: keyword spotting, visual wake words, image classiﬁcation, and anomaly detection.}
}
@article{banbury2021mlperf,
  title   = {Mlperf tiny benchmark},
  author  = {Banbury, Colby and Reddi, Vijay Janapa and Torelli, Peter and Holleman, Jeremy and Jeffries, Nat and Kiraly, Csaba and Montino, Pietro and Kanter, David and Ahmed, Sebastian and Pau, Danilo and others},
  journal = {arXiv preprint arXiv:2106.07597},
  year    = {2021}
}
@inproceedings{basu2022spiking,
  title        = {Spiking neural network integrated circuits: A review of trends and future directions},
  author       = {Basu, Arindam and Deng, Lei and Frenkel, Charlotte and Zhang, Xueyong},
  booktitle    = {2022 IEEE Custom Integrated Circuits Conference (CICC)},
  pages        = {1--8},
  year         = {2022},
  organization = {IEEE}
}
@inproceedings{beyer2020fefet,
  title        = {FeFET: A versatile CMOS compatible device with game-changing potential},
  author       = {Beyer, Sven and D{\"u}nkel, Stefan and Trentzsch, Martin and M{\"u}ller, Johannes and Hellmich, Andreas and Utess, Dirk and Paul, Jan and Kleimaier, Dominik and Pellerin, John and M{\"u}ller, Stefan and others},
  booktitle    = {2020 IEEE International Memory Workshop (IMW)},
  pages        = {1--4},
  year         = {2020},
  organization = {IEEE}
}
@inproceedings{biswas2022area,
  title        = {An area-efficient 6T-SRAM based compute-in-memory architecture with reconfigurable SAR ADCs for energy-efficient deep neural networks in edge ML applications},
  author       = {Biswas, Avishek and Sanghvi, Hetul and Mehendale, Mahesh and Preet, G},
  booktitle    = {2022 IEEE Custom Integrated Circuits Conference (CICC)},
  pages        = {1--2},
  year         = {2022},
  organization = {IEEE}
}
@book{book_key,
  address   = {City},
  publisher = {Publisher},
  author    = {Smith, John},
  title     = {Book title},
  year      = {2012},
  volume    = {3},
  series    = {2},
  edition   = {1},
  pages     = {123--200},
  month     = {January}
}
@article{Cai_2022,
  title    = {Enable Deep Learning on Mobile Devices: Methods, Systems, and Applications},
  year     = {2022},
  author   = {Han Cai and Ji Lin and Yujun Lin and Zhijian Liu and Haotian Tang and Hanrui Wang and Ligeng Zhu and Song Han},
  doi      = {10.1145/3486618},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {4214951654},
  journal  = {ACM Transactions on Design Automation of Electronic Systems},
  abstract = {Deep neural networks (DNNs) have achieved unprecedented success in the field of artificial intelligence (AI), including computer vision, natural language processing, and speech recognition. However, their superior performance comes at the considerable cost of computational complexity, which greatly hinders their applications in many resource-constrained devices, such as mobile phones and Internet of Things (IoT) devices. Therefore, methods and techniques that are able to lift the efficiency bottleneck while preserving the high accuracy of DNNs are in great demand to enable numerous edge AI applications. This article provides an overview of efficient deep learning methods, systems, and applications. We start from introducing popular model compression methods, including pruning, factorization, quantization, as well as compact model design. To reduce the large design cost of these manual solutions, we discuss the AutoML framework for each of them, such as neural architecture search (NAS) and automated pruning and quantization. We then cover efficient on-device training to enable user customization based on the local data on mobile devices. Apart from general acceleration techniques, we also showcase several task-specific accelerations for point cloud, video, and natural language processing by exploiting their spatial sparsity and temporal/token redundancy. Finally, to support all these algorithmic advancements, we introduce the efficient deep learning system design from both software and hardware perspectives.}
}
@inproceedings{cai2020rethinking,
  title     = {Rethinking differentiable search for mixed-precision neural networks},
  author    = {Cai, Zhaowei and Vasconcelos, Nuno},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages     = {2349--2358},
  year      = {2020}
}
@article{chen2016eyeriss,
  title     = {Eyeriss: An energy-efficient reconfigurable accelerator for deep convolutional neural networks},
  author    = {Chen, Yu-Hsin and Krishna, Tushar and Emer, Joel S and Sze, Vivienne},
  journal   = {IEEE journal of solid-state circuits},
  volume    = {52},
  number    = {1},
  pages     = {127--138},
  year      = {2016},
  publisher = {IEEE}
}
@inproceedings{chih202116,
  title        = {16.4 An 89TOPS/W and 16.3 TOPS/mm 2 all-digital SRAM-based full-precision compute-in memory macro in 22nm for machine-learning edge applications},
  author       = {Chih, Yu-Der and Lee, Po-Hao and Fujiwara, Hidehiro and Shih, Yi-Chun and Lee, Chia-Fu and Naous, Rawan and Chen, Yu-Lin and Lo, Chieh-Pu and Lu, Cheng-Han and Mori, Haruki and others},
  booktitle    = {2021 IEEE International Solid-State Circuits Conference (ISSCC)},
  volume       = {64},
  pages        = {252--254},
  year         = {2021},
  organization = {IEEE}
}
@article{chiu20204,
  title     = {A 4-Kb 1-to-8-bit configurable 6T SRAM-based computation-in-memory unit-macro for CNN-based AI edge processors},
  author    = {Chiu, Yen-Cheng and Zhang, Zhixiao and Chen, Jia-Jing and Si, Xin and Liu, Ruhui and Tu, Yung-Ning and Su, Jian-Wei and Huang, Wei-Hsing and Wang, Jing-Hong and Wei, Wei-Chen and others},
  journal   = {IEEE Journal of Solid-State Circuits},
  volume    = {55},
  number    = {10},
  pages     = {2790--2801},
  year      = {2020},
  publisher = {IEEE}
}
@inproceedings{chua2015delay,
  title        = {Delay variation compensation through error correction using razor},
  author       = {Chua, Adelson N and Maestro, Rico Jossel M and Alba, Mark Earvin V and Lofamia, Wes Vernon V and Pelayo, Bernard Raymond D and Fabay, Ken Bryan F and Jardin, John Cris F and Jocson, Kervin John C and Madamba, Joy Alinda R and Hizon, John Richard E and others},
  booktitle    = {2015 International Workshop on CMOS Variability (VARI)},
  pages        = {5--8},
  year         = {2015},
  organization = {IEEE}
}
@article{conti2024open,
  title   = {Open-Source Heterogeneous SoCs for AI: The PULP Platform Experience},
  author  = {Conti, Francesco and Garofalo, Angelo and Rossi, Davide and Tagliavini, Giuseppe and Benini, Luca},
  journal = {arXiv preprint arXiv:2412.20391},
  year    = {2024}
}
@article{d2024denram,
  title     = {DenRAM: neuromorphic dendritic architecture with RRAM for efficient temporal processing with delays},
  author    = {D’agostino, Simone and Moro, Filippo and Torchet, Tristan and Demira{\u{g}}, Yi{\u{g}}it and Grenouillet, Laurent and Castellani, Niccol{\`o} and Indiveri, Giacomo and Vianello, Elisa and Payvand, Melika},
  journal   = {Nature communications},
  volume    = {15},
  number    = {1},
  pages     = {3446},
  year      = {2024},
  publisher = {Nature Publishing Group UK London}
}@article{dazzi2021efficient,
  title     = {Efficient pipelined execution of CNNs based on in-memory computing and graph homomorphism verification},
  author    = {Dazzi, Martino and Sebastian, Abu and Parnell, Thomas and Francese, Pier Andrea and Benini, Luca and Eleftheriou, Evangelos},
  journal   = {IEEE Transactions on Computers},
  volume    = {70},
  number    = {6},
  pages     = {922--935},
  year      = {2021},
  publisher = {IEEE}
}@inproceedings{dimayuga2017study,
  title        = {A study on the effects of dynamic voltage and frequency scaling on an error detection block for a LoRa communications system},
  author       = {Dimayuga, Jahn Carroll and Fernandez, Ian Christian and Lopez, Alfonso Elias and Pangilinan, Rafael and Alarcon, Louis and de Leon, Maria Theresa and Maestro, Rico Jossel and Rosales, Marc and Densing, Chris Vincent},
  booktitle    = {TENCON 2017-2017 IEEE Region 10 Conference},
  pages        = {1538--1543},
  year         = {2017},
  organization = {IEEE}
}@article{Fei_2016,
  title    = {Research on speech emotion recognition based on deep auto-encoder},
  year     = {2016},
  author   = {Wang Fei and Xiaofeng Ye and Zhaoyu Sun and Yujia Huang and Xing Zhang and Shengxing Shang},
  doi      = {10.1109/cyber.2016.7574841},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {2526834636},
  journal  = {2016 IEEE International Conference on Cyber Technology in Automation, Control, and Intelligent Systems (CYBER)},
  abstract = {Good features are critical for the research of speech emotion recognition. This paper based on the theory of deep learning, and phonetic features were extracted by using the method of deep auto-encoder (DAE). In this paper, a deep auto-encoder containing five hidden layers was designed. To get the input data, we divided the audio into short frames, each frame of speech emotion signal was then decomposed with wavelet, and was calculated the Fourier transform. Higher features were learned with deep automatic encoder, and some traditional features such as MFCC, LPCC were also extracted. With high-level features and traditional features, support vector machine was used for classification and recognition. Compared with the traditional features, the results show that the highest recognition accuracy rate can be reached 86.41%.}
}@inproceedings{ferro2024precision,
  title        = {A Precision-Optimized Fixed-Point Near-Memory Digital Processing Unit for Analog In-Memory Computing},
  author       = {Ferro, Elena and Vasilopoulos, Athanasios and Lammie, Corey and Le Gallo, Manuel and Benini, Luca and Boybat, Irem and Sebastian, Abu},
  booktitle    = {2024 IEEE International Symposium on Circuits and Systems (ISCAS)},
  pages        = {1--5},
  year         = {2024},
  organization = {IEEE}
}@inproceedings{fujiwara20225,
  title        = {A 5-nm 254-TOPS/W 221-TOPS/mm 2 fully-digital computing-in-memory macro supporting wide-range dynamic-voltage-frequency scaling and simultaneous MAC and write operations},
  author       = {Fujiwara, Hidehiro and Mori, Haruki and Zhao, Wei-Chang and Chuang, Mei-Chen and Naous, Rawan and Chuang, Chao-Kai and Hashizume, Takeshi and Sun, Dar and Lee, Chia-Fu and Akarvardar, Kerem and others},
  booktitle    = {2022 IEEE International Solid-State Circuits Conference (ISSCC)},
  volume       = {65},
  pages        = {1--3},
  year         = {2022},
  organization = {IEEE}
}@inproceedings{gao2024fly,
  title        = {On-the-Fly Data Layout Conversion for GEMM on AI Accelerators},
  author       = {Gao, Fang and Yue, Xingyu and Tang, Chenchen and Chen, Hongyi and Wang, Kai-Ting Amy and Abdelrahman, Tarek S},
  booktitle    = {2024 IEEE International Symposium on Parallel and Distributed Processing with Applications (ISPA)},
  pages        = {484--493},
  year         = {2024},
  organization = {IEEE}
}@article{garofalo2022heterogeneous,
  title     = {A heterogeneous in-memory computing cluster for flexible end-to-end inference of real-world deep neural networks},
  author    = {Garofalo, Angelo and Ottavi, Gianmarco and Conti, Francesco and Karunaratne, Geethan and Boybat, Irem and Benini, Luca and Rossi, Davide},
  journal   = {IEEE Journal on Emerging and Selected Topics in Circuits and Systems},
  volume    = {12},
  number    = {2},
  pages     = {422--435},
  year      = {2022},
  publisher = {IEEE}
}@inproceedings{gibson2020optimizing,
  title        = {Optimizing grouped convolutions on edge devices},
  author       = {Gibson, Perry and Cano, Jose and Turner, Jack and Crowley, Elliot J and OBoyle, Michael and Storkey, Amos},
  booktitle    = {2020 IEEE 31st International Conference on Application-specific Systems, Architectures and Processors (ASAP)},
  pages        = {189--196},
  year         = {2020},
  organization = {IEEE}
}@article{Grozdic_2017,
  title    = {Whispered Speech Recognition Using Deep Denoising Autoencoder and Inverse Filtering},
  year     = {2017},
  author   = {Dorde T. Grozdic and Slobodan T. Jovicic and Slobodan T. Jovicic},
  doi      = {10.1109/taslp.2017.2738559},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {2768731046},
  journal  = {IEEE Transactions on Audio, Speech, and Language Processing},
  abstract = {Due to the profound differences between acoustic characteristics of neutral and whispered speech, the performance of traditional automatic speech recognition (ASR) systems trained on neutral speech degrades significantly when whisper is applied. In order to deeply analyze this mismatched train/test situation and to develop an efficient way for whisper recognition, this study first analyzes acoustic characteristics of whispered speech, addresses the problems of whispered speech recognition in mismatched conditions, and then proposes a new robust cepstral features and preprocessing approach based on deep denoising autoencoder (DDAE) that enhance whisper recognition. The experimental results confirm that Teager-energy-based cepstral features, especially TECCs, are more robust and better whisper descriptors than traditional Mel-frequency cepstral coefficients (MFCC). Further detailed analysis of cepstral distances, distributions of cepstral coefficients, confusion matrices, and experiments with inverse filtering, prove that voicing in speech stimuli is the main cause of word misclassification in mismatched train/test scenarios. The new framework based on DDAE and TECC feature, significantly improves whisper recognition accuracy and outperforms traditional MFCC and GMM-HMM (Gaussian mixture density—Hidden Markov model) baseline, resulting in an absolute 31% improvement of whisper recognition accuracy. The achieved word recognition rate in neutral/whisper scenario is 92.81%.}
}@article{Hajri_2019,
  title    = {RRAM Device Models: A Comparative Analysis With Experimental Validation},
  year     = {2019},
  author   = {Basma Hajri and Hassen Aziza and Mohammad M. Mansour and Mohammad M. Mansour and Ali Chehab},
  doi      = {10.1109/access.2019.2954753},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {2991418313},
  journal  = {IEEE Access},
  abstract = {Resistive Random Access Memories (RRAM) have recently shown outstanding characteristics such as high-scalability, high-speed, high-density, and low-energy operation. A simple and accurate model is crucial for rapid design and verification when using RRAM devices at the circuit level. The appropriate model selection gives insight into the behavior of RRAM as well as the efficient use of its unique properties. This work intends to guide the circuit designers in selecting the most appropriate RRAM model for their applications. We introduce a complete set of evaluation criteria for memristor models: type of model, type of switching, genericity, complexity, compatibility with actual physical switching mechanisms, linearity, symmetry, voltage/current control, hard set/soft reset, support electroforming, support for high programming signal frequencies, existence of a threshold, voltage level, timing dependence, temperature dependence and variability. This study compares the main existing RRAM models and summarizes the results in a table showing the main features and limitations of each model. Through extensive simulations and comparisons with experimental data, we provide an analysis and a validation of the reviewed models within the same simulation environment, ranging from individual elementary cells to large memory arrays. Furthermore, we provide a single and unique Verilog-A code integrating all the compared models.}
}

@inproceedings{han2022comprehensive,
  title        = {Comprehensive Design-oriented FDSOI EKV Model},
  author       = {Han, Hung-Chi and D'Amico, Antonio and Enz, Christian},
  booktitle    = {2022 29th International Conference on Mixed Design of Integrated Circuits and System (MIXDES)},
  pages        = {40--44},
  year         = {2022},
  organization = {IEEE}
}@article{He_2016,
  title    = {Deep Residual Learning for Image Recognition},
  year     = {2016},
  author   = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  doi      = {10.1109/cvpr.2016.90},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {2194775991},
  journal  = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers—8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.}
}
@article{hosny2023power,
  title     = {A power-efficient dynamic-time current mode comparator},
  author    = {Hosny, Ahmed and Farag, Fathi A and Wahba, Ahmed and Mohamed, Ahmed Reda},
  journal   = {AEU-International Journal of Electronics and Communications},
  volume    = {171},
  pages     = {154934},
  year      = {2023},
  publisher = {Elsevier}
}
@article{houshmand2022diana,
  title     = {Diana: An end-to-end hybrid digital and analog neural network soc for the edge},
  author    = {Houshmand, Pouya and Sarda, Giuseppe M and Jain, Vikram and Ueyoshi, Kodai and Papistas, Ioannis A and Shi, Man and Zheng, Qilin and Bhattacharjee, Debjyoti and Mallik, Arindam and Debacker, Peter and others},
  journal   = {IEEE Journal of Solid-State Circuits},
  volume    = {58},
  number    = {1},
  pages     = {203--215},
  year      = {2022},
  publisher = {IEEE}
}
@article{hu2024central,
  title     = {The central role of tilted anisotropy for field-free spin--orbit torque switching of perpendicular magnetization},
  author    = {Hu, Chen-Yu and Chen, Wei-De and Liu, Yan-Ting and Huang, Chao-Chung and Pai, Chi-Feng},
  journal   = {NPG Asia Materials},
  volume    = {16},
  number    = {1},
  pages     = {1},
  year      = {2024},
  publisher = {Springer Japan Tokyo}
}
@article{Hung_2021,
  title    = {A four-megabit compute-in-memory macro with eight-bit precision based on CMOS and resistive random-access memory for AI edge devices},
  year     = {2021},
  author   = {Je-Min Hung and Cheng-Xin Xue and Hui-Yao Kao and Yen-Hsiang Huang and Fu-Chun Chang and Sheng-Po Huang and Ta-Wei Liu and Chuan-Jia Jhang and Chin-Yi Su and Win-San Khwa and Chung-Chuang Lo and Chung-Chuan Lo and Ren-Shuo Liu and Chih-Cheng Hsieh and Kea-Tiong Tang and Mon-Shu Ho and Chou Chung-Cheng and Yu-Der Chih and Tung-Cheng Chang and Meng-Fan Chang},
  doi      = {10.1038/s41928-021-00676-9},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {4200611376},
  journal  = {Nature Electronics},
  abstract = {Non-volatile computing-in-memory (nvCIM) architecture can reduce the latency and energy consumption of artificial intelligence computation by minimizing the movement of data between the processor and memory. However, artificial intelligence edge devices with high inference accuracy require large-capacity nvCIM macros capable of high-bit-precision dot-product operations. Here we report a four-megabit nvCIM macro that combines memory cells with peripheral circuitry and is based on 22-nm-foundry binary resistive random-access memory devices and complementary metal–oxide–semiconductor (CMOS) processes. The fully CMOS-integrated macro features an asymmetrically modulated input-and-calibration scheme, a calibrated-and-weighted current-to-voltage stacking read scheme, and input-shaping hardware to overcome the challenges involved in designing large-capacity nvCIM macros with high bit precision. The macro offers latencies between 5.2 and 15.2 ns and energy efficiency between 194.4 and 15.6 tera-operations per second per watt in binary to 8-bit-input–8-bit-weight dot-product operations.}
}
@article{Ito_2020,
  title    = {AN ON-DEVICE FEDERATED LEARNING APPROACH FOR COOPERATIVE ANOMALY DETECTION},
  year     = {2020},
  author   = {Rei Ito and Mineto Tsukada and Hiroki Matsutani},
  doi      = {null},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {3007780034},
  journal  = {arXiv: Learning},
  abstract = {Most edge AI focuses on prediction tasks on resource-limited edge devices, while the training is done at server machines, so retraining a model on the edge devices to reflect environmental changes is a complicated task. To follow such a concept drift, a neural-network based on-device learning approach is recently proposed, so that edge devices train incoming data at runtime to update their model. In this case, since a training is done at distributed edge devices, the issue is that only a limited amount of training data can be used for each edge device. To address this issue, one approach is a cooperative learning or federated learning, where edge devices exchange their trained results and update their model by using those collected from the other devices. In this paper, as an on-device learning algorithm, we focus on OS-ELM (Online Sequential Extreme Learning Machine) and combine it with Autoencoder for anomaly detection. We extend it for an on-device federated learning so that edge devices exchange their trained results and update their model by using those collected from the other edge devices. Experimental results using a driving dataset of cars demonstrate that the proposed on-device federated learning can produce more accurate model by combining trained results from multiple edge devices compared to a single model.}
}@article{Ito_2021,
  title    = {An On-Device Federated Learning Approach for Cooperative Model Update Between Edge Devices},
  year     = {2021},
  author   = {Rei Ito and Mineto Tsukada and Hiroki Matsutani},
  doi      = {10.1109/access.2021.3093382},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {3176734149},
  journal  = {IEEE Access},
  abstract = {Most edge AI focuses on prediction tasks on resource-limited edge devices while the training is done at server machines. However, retraining or customizing a model is required at edge devices as the model is becoming outdated due to environmental changes over time. To follow such a concept drift, a neural-network based on-device learning approach is recently proposed, so that edge devices train incoming data at runtime to update their model. In this case, since a training is done at distributed edge devices, the issue is that only a limited amount of training data can be used for each edge device. To address this issue, one approach is a cooperative learning or federated learning, where edge devices exchange their trained results and update their model by using those collected from the other devices. In this paper, as an on-device learning algorithm, we focus on OS-ELM (Online Sequential Extreme Learning Machine) to sequentially train a model based on recent samples and combine it with autoencoder for anomaly detection. We extend it for an on-device federated learning so that edge devices can exchange their trained results and update their model by using those collected from the other edge devices. This cooperative model update is one-shot while it can be repeatedly applied to synchronize their model. Our approach is evaluated with anomaly detection tasks generated from a driving dataset of cars, a human activity dataset, and MNIST dataset. The results demonstrate that the proposed on-device federated learning can produce a merged model by integrating trained results from multiple edge devices as accurately as traditional backpropagation based neural networks and a traditional federated learning approach with lower computation or communication cost.}
}@inproceedings{jacob2018quantization,
  title     = {Quantization and training of neural networks for efficient integer-arithmetic-only inference},
  author    = {Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {2704--2713},
  year      = {2018}
}@article{jiang2020c3sram,
  title     = {C3SRAM: An in-memory-computing SRAM macro based on robust capacitive coupling computing mechanism},
  author    = {Jiang, Zhewei and Yin, Shihui and Seo, Jae-Sun and Seok, Mingoo},
  journal   = {IEEE Journal of Solid-State Circuits},
  volume    = {55},
  number    = {7},
  pages     = {1888--1897},
  year      = {2020},
  publisher = {IEEE}
}


@article{korf2010optimal,
  title     = {Optimal rectangle packing},
  author    = {Korf, Richard E and Moffitt, Michael D and Pollack, Martha E},
  journal   = {Annals of Operations Research},
  volume    = {179},
  pages     = {261--295},
  year      = {2010},
  publisher = {Springer}
}@inproceedings{koryakovskiy2023one,
  title     = {One-shot model for mixed-precision quantization},
  author    = {Koryakovskiy, Ivan and Yakovleva, Alexandra and Buchnev, Valentin and Isaev, Temur and Odinokikh, Gleb},
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages     = {7939--7949},
  year      = {2023}
}

@article{lammie2025lionheart,
  title     = {Lionheart: A layer-based mapping framework for heterogeneous systems with analog in-memory computing tiles},
  author    = {Lammie, Corey and Wang, Yuxuan and Ponzina, Flavio and Klein, Joshua and Benmeziane, Hadjer and Zapater, Marina and Boybat, Irem and Sebastian, Abu and Ansaloni, Giovanni and Atienza, David},
  journal   = {IEEE Transactions on Emerging Topics in Computing},
  year      = {2025},
  publisher = {IEEE}
}

@article{lee2018unpu,
  title     = {UNPU: An energy-efficient deep neural network accelerator with fully variable weight bit precision},
  author    = {Lee, Jinmook and Kim, Changhyeon and Kang, Sanghoon and Shin, Dongjoo and Kim, Sangyeob and Yoo, Hoi-Jun},
  journal   = {IEEE Journal of Solid-State Circuits},
  volume    = {54},
  number    = {1},
  pages     = {173--185},
  year      = {2018},
  publisher = {IEEE}
}

@article{Lin_2022,
  title    = {On-Device Training Under 256KB Memory},
  year     = {2022},
  author   = {Ji Lin and Ligeng Zhu and Wei-Ming Chen and Wei-Chen Wang and Chuang Gan and Song Han},
  doi      = {10.48550/arxiv.2206.15472},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {null},
  journal  = {ArXiv},
  abstract = {On-device training enables the model to adapt to new data collected from the sensors by ﬁne-tuning a pre-trained model. However, the training memory consumption is prohibitive for IoT devices that have tiny memory resources. We propose an algorithm-system co-design framework to make on-device training pos-sible with only 256KB of memory. On-device training faces two unique challenges: (1) the quantized graphs of neural networks are hard to optimize due to mixed bit-precision and the lack of normalization; (2) the limited hardware resource (memory and computation) does not allow full backward computation. To cope with the optimization difﬁculty, we propose Quantization-Aware Scaling to calibrate the gradient scales and stabilize quantized training. To reduce the memory footprint, we propose Sparse Update to skip the gradient computation of less important layers and sub-tensors. The algorithm innovation is implemented by a lightweight training system, Tiny Training Engine , which prunes the backward computation graph to support sparse updates and ofﬂoad the runtime auto-differentiation to compile time. Our framework is the ﬁrst practical solution for on-device transfer learning of visual recognition on tiny IoT devices ( e.g ., a microcontroller with only 256KB SRAM), using less than 1/100 of the memory of existing frameworks while matching the accuracy of cloud training+edge deployment for the tinyML application VWW [21]. Our study enables IoT devices to not only perform inference but also continuously adapt to new data for on-device lifelong learning. when simulated on GPUs since it cannot leverage the hardware parallelism, making experiments slow. We study the performance}
}

@article{lin2020mcunet,
  title   = {Mcunet: Tiny deep learning on iot devices},
  author  = {Lin, Ji and Chen, Wei-Ming and Lin, Yujun and Gan, Chuang and Han, Song and others},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {33},
  pages   = {11711--11722},
  year    = {2020}
}

@article{Liu_2020,
  title    = {33.2 A Fully Integrated Analog ReRAM Based 78.4TOPS/W Compute-In-Memory Chip with Fully Parallel MAC Computing},
  year     = {2020},
  author   = {Qi Liu and Qi Liu and Qi Liu and Bin Gao and Bin Gao and Peng Yao and Dong Wu and Dong Wu and Junren Chen and Yachuan Pang and Wenqiang Zhang and Yan Liao and Cheng-Xin Xue and Wei-Hao Chen and Jianshi Tang and Yu Wang and Meng-Fan Chang and He Qian and Huaqiang Wu},
  doi      = {10.1109/isscc19947.2020.9062953},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {3015982917},
  journal  = {2020 IEEE International Solid- State Circuits Conference - (ISSCC)},
  abstract = {Non-volatile memory (NVM) based computing-in-memory (CIM) shows significant advantages in handling deep learning tasks for artificial intelligence (AI) applications. To overcome the decreasing cost effectiveness of transistor scaling and the intrinsic inefficiency of data-shuttling in the von-Neumann architecture, CIM is proposed to realize high-speed and low-power system with parallel multiplication accumulation (MAC) computing [1] [2]. However, current demonstrations are mainly based on single macro and present limited computing parallelism. Realizing a fully-integrated CIM chip with a complete neural network model is still missing. The major challenges lie in: (1) The IR drop and transient errors when carrying out MAC operations in non-volatile memory arrays decrease the computing accuracy and further limit the parallelism; (2) The inefficiency of the interface blocks between different arrays due to the power overhead of the A/D and D/A converters (shown in Fig. 33.2.1). To address these challenges, this work proposes: (1) A sign-weighted 2T2R (SW-2T2R) array to reduce IR drop by decreasing the accumulative SL current (ISL), and eventually boost the computing parallelism; (2) a low-power interface design with resolution-adjustable LPAR-ADC to realize flexible tradeoff between system accuracy and power consumption. In this manner, this work implements a fully-integrated 784-100-10 MLP model on an integrated CIM chip with158.8kb analog ReRAMs. This chip realizes high recognition accuracy (94.4%) on MNIST database, high inference speed (77 µs/lmage), and 78.4 TOPS/W peak energy efficiency. The CMOS circuits are fabricated in a 130nm process.}
}

@article{Ma_2019,
  title    = {Sensing, Computing, and Communications for Energy Harvesting IoTs: A Survey},
  year     = {2019},
  author   = {Dong Ma and Guohao Lan and Mahbub Hassan and Wen Hu and Sajal K. Das},
  doi      = {10.1109/comst.2019.2962526},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {2996943723},
  journal  = {IEEE Communications Surveys and Tutorials},
  abstract = {With the growing number of deployments of Internet of Things (IoT) infrastructure for a wide variety of applications, the battery maintenance has become a major limitation for the sustainability of such infrastructure. To overcome this problem, energy harvesting offers a viable alternative to autonomously power IoT devices, resulting in a number of battery-less energy harvesting IoTs (or EH-IoTs) appearing in the market in recent years. Standards activities are also underway, which involve wireless protocol design suitable for EH-IoTs as well as testing procedures for various energy harvesting methods. Despite the early commercial and standards activities, IoT sensing, computing and communications under unpredictable power supply still face significant research challenges. This paper systematically surveys recent advances in EH-IoTs from several perspectives. First, it reviews the recent commercial developments for EH-IoT in terms of both products and services, followed by initial standards activities in this space. Then it surveys methods that enable the use of energy harvesting hardware as a proxy for conventional sensors to detect contexts in energy efficient manner. Next it reviews the advancements in efficient checkpointing and timekeeping for intermittently powered IoT devices. We also survey recent research in novel wireless communication techniques for EH-IoTs, such as the applications of reinforcement learning to optimize power allocations on-the-fly under unpredictable energy productions, and packet-less IoT communications and backscatter communication techniques for energy impoverished environments. The paper is concluded with a discussion of future research directions.}
}

@misc{markuspython,
  title  = {Python-Skill Bridge},
  author = {Markus, T and Buwen, N}
}

@article{Matsutani_2022,
  title    = {On-Device Learning: A Neural Network Based Field-Trainable Edge AI},
  year     = {2022},
  author   = {Hiroki Matsutani and Mineto Tsukada and Masaaki Kondo},
  doi      = {10.48550/arxiv.2203.01077},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {null},
  journal  = {ArXiv},
  abstract = {In real-world edge AI applications, their accuracy is often affected by various environmental factors, such as noises, location/calibration of sensors, and time-related changes. This article introduces a neural network based on-device learning approach to address this issue without going deep. Our approach is quite different from de facto backpropagation based training but tailored for low-end edge devices. This article introduces its algorithm and implementation on a wireless sensor node consisting of Raspberry Pi Pico and low-power wireless module. Experiments using vibration patterns of rotating machines demonstrate that retraining by the on-device learning signiﬁcantly improves an anomaly detection accuracy at a noisy environment while saving computation and communication costs for low power.}
}

@article{Mochida_2018,
  title    = {A 4M Synapses integrated Analog ReRAM based 66.5 TOPS/W Neural-Network Processor with Cell Current Controlled Writing and Flexible Network Architecture},
  year     = {2018},
  author   = {Reiji Mochida and Kazuyuki Kouno and Yuriko Hayata and Masayoshi Nakayama and Takashi Ono and Hitoshi Suwa and Ryutaro Yasuhara and Koji Katayama and Takumi Mikawa and Yasushi Gohou},
  doi      = {10.1109/vlsit.2018.8510676},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {2898994846},
  journal  = {2018 IEEE Symposium on VLSI Technology},
  abstract = {This paper presents low-power neural-network (NN) processor using ReRAM to store weights as analog resistance for future AI computing. We propose ReRAM perceptron circuit for realizing large scale integration, highly accurate cell current controlled writing scheme, and flexible network architecture (FNA) in which any NNs can be configured. Fabricated 180nm test chip shows well-controlled analog cell current with linear 30μA dynamic range and 0.59μA variation of 1 sigma, results in 90.8% MNIST numerical recognition rate. Furthermore, 4M synapses integrated 40nm test chip achieves lower analog cell current and 66.5 TOPS/W power efficiency.}
}

@misc{nanoHUB.org19,
  title  = {Stanford University Resistive-Switching Random Access Memory (RRAM) Verilog-A Model},
  month  = {Oct},
  url    = {https://nanohub.org/publications/19/1},
  year   = {2014},
  doi    = {doi:/10.4231/D37H1DN48},
  author = {Zizhen Jiang, Philip Wong}
}

@article{palossi201964,
  title     = {A 64-mw dnn-based visual navigation engine for autonomous nano-drones},
  author    = {Palossi, Daniele and Loquercio, Antonio and Conti, Francesco and Flamand, Eric and Scaramuzza, Davide and Benini, Luca},
  journal   = {IEEE Internet of Things Journal},
  volume    = {6},
  number    = {5},
  pages     = {8357--8371},
  year      = {2019},
  publisher = {IEEE}
}

@article{Patterson_1997,
  title    = {A case for intelligent RAM},
  year     = {1997},
  author   = {David A. Patterson and Thomas Anderson and Neal Cardwell and Richard Fromm and Kimberly Keeton and Kimberly Keeton and Christoforos Kozyrakis and Christos Kozyrakis and Randi Thomas and Katherine Yelick},
  doi      = {10.1109/40.592312},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {2112980698},
  journal  = {IEEE Micro},
  abstract = {Two trends call into question the current practice of fabricating microprocessors and DRAMs as different chips on different fabrication lines. The gap between processor and DRAM speed is growing at 50% per year; and the size and organization of memory on a single DRAM chip is becoming awkward to use, yet size is growing at 60% per year. Intelligent RAM, or IRAM, merges processing and memory into a single chip to lower memory latency, increase memory bandwidth, and improve energy efficiency. It also allows more flexible selection of memory size and organization, and promises savings in board area. This article reviews the state of microprocessors and DRAMs today, explores some of the opportunities and challenges for IRAMs, and finally estimates performance and energy efficiency of three IRAM designs.}
}

@article{pedretti2021memory,
  title     = {In-memory computing with resistive memory circuits: Status and outlook},
  author    = {Pedretti, Giacomo and Ielmini, Daniele},
  journal   = {Electronics},
  volume    = {10},
  number    = {9},
  pages     = {1063},
  year      = {2021},
  publisher = {MDPI}
}

@article{perumal2023tunable,
  title     = {Tunable conversion of topological spin texture from domain wall pair for magnetic memory application in specially designed magnetic nanotracks},
  author    = {Perumal, Hari Prasanth and Sankaran Kunnath, Syamlal and Priyanka, Babu and Sinha, Jaivardhan},
  journal   = {ACS Applied Electronic Materials},
  volume    = {5},
  number    = {7},
  pages     = {3641--3649},
  year      = {2023},
  publisher = {ACS Publications}
}

@article{pourmand2024laplace,
  title   = {Laplace-HDC: Understanding the geometry of binary hyperdimensional computing},
  author  = {Pourmand, Saeid and Whiting, Wyatt D and Aghasi, Alireza and Marshall, Nicholas F},
  journal = {arXiv preprint arXiv:2404.10759},
  year    = {2024}
}

@article{prabhu2022chimera,
  title     = {CHIMERA: A 0.92-TOPS, 2.2-TOPS/W edge AI accelerator with 2-MByte on-chip foundry resistive RAM for efficient training and inference},
  author    = {Prabhu, Kartik and Gural, Albert and Khan, Zainab F and Radway, Robert M and Giordano, Massimo and Koul, Kalhan and Doshi, Rohan and Kustin, John W and Liu, Timothy and Lopes, Gregorio B and others},
  journal   = {IEEE Journal of Solid-State Circuits},
  volume    = {57},
  number    = {4},
  pages     = {1013--1026},
  year      = {2022},
  publisher = {IEEE}
}

@article{radway2021illusion,
  title     = {Illusion of large on-chip memory by networked computing chips for neural network inference},
  author    = {Radway, Robert M and Bartolo, Andrew and Jolly, Paul C and Khan, Zainab F and Le, Binh Q and Tandon, Pulkit and Wu, Tony F and Xin, Yunfeng and Vianello, Elisa and Vivet, Pascal and others},
  journal   = {Nature Electronics},
  volume    = {4},
  number    = {1},
  pages     = {71--80},
  year      = {2021},
  publisher = {Nature Publishing Group UK London}
}

@article{raghavan2009empire,
  title     = {EMPIRE: Empirical power/area/timing models for register files},
  author    = {Raghavan, Praveen and Lambrechts, Andy and Jayapala, Murali and Catthoor, Francky and Verkest, Diederik},
  journal   = {Microprocessors and Microsystems},
  volume    = {33},
  number    = {4},
  pages     = {295--300},
  year      = {2009},
  publisher = {Elsevier}
}

@article{ray2021review,
  title     = {A review on TinyML: State-of-the-art and prospects},
  author    = {Ray, Partha Pratim},
  journal   = {Journal of King Saud University-Computer and Information Sciences},
  year      = {2021},
  publisher = {Elsevier}
}

@inproceedings{sandler2018mobilenetv2,
  title     = {Mobilenetv2: Inverted residuals and linear bottlenecks},
  author    = {Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {4510--4520},
  year      = {2018}
}

@inproceedings{schuler2022grouped,
  title     = {Grouped Pointwise Convolutions Reduce Parameters in Convolutional Neural Networks},
  author    = {Schuler, Joao Paulo Schwarz and Romani, Santiago and Abdel-Nasser, Mohamed and Rashwan, Hatem and Puig, Domenec},
  booktitle = {MENDEL},
  volume    = {28},
  number    = {1},
  pages     = {23--31},
  year      = {2022}
}

@article{sharma2021electrically,
  title     = {Electrically connected spin-torque oscillators array for 2.4 GHz WiFi band transmission and energy harvesting},
  author    = {Sharma, Raghav and Mishra, Rahul and Ngo, Tung and Guo, Yong-Xin and Fukami, Shunsuke and Sato, Hideo and Ohno, Hideo and Yang, Hyunsoo},
  journal   = {Nature communications},
  volume    = {12},
  number    = {1},
  pages     = {2924},
  year      = {2021},
  publisher = {Nature Publishing Group UK London}
}

@article{Sheridan_2017,
  title    = {Sparse coding with Memristor networks},
  year     = {2017},
  author   = {Patrick Sheridan and Fuxi Cai and Chao Du and Chao Du and Wen Ma and Chao Du and Zhengya Zhang and Wei Lu},
  doi      = {10.1038/nnano.2017.83},
  pmid     = {28530717},
  pmcid    = {null},
  mag_id   = {2617093514},
  journal  = {Nature Nanotechnology},
  abstract = {Sparse representation of information performs powerful feature extraction on high-dimensional data and is of interest for applications in signal processing, machine vision, object recognition, and neurobiology. Sparse coding is a mechanism by which biological neural systems can efficiently process complex sensory data while consuming very little power. Sparse coding algorithms in a bio-inspired approach can be implemented in a crossbar array of memristors (resistive memory devices). This network enables efficient implementation of pattern matching and lateral neuron inhibition, allowing input data to be sparsely encoded using neuron activities and stored dictionary elements. The reconstructed input can be obtained by performing a backward pass through the same crossbar matrix using the neuron activity vector as input. Different dictionary sets can be trained and stored in the same system, depending on the nature of the input signals. Using the sparse coding algorithm, natural image processing is performed based on a learned dictionary.}
}

@article{Shoeibi_2021,
  title    = {A comprehensive comparison of handcrafted features and convolutional autoencoders for epileptic seizures detection in EEG signals},
  year     = {2021},
  author   = {Afshin Shoeibi and Afshin Shoeibi and Navid Ghassemi and Roohallah Alizadehsani and Modjtaba Rouhani and Hossein Hosseini-Nejad and Abbas Khosravi and Maryam Panahiazar and Saeid Nahavandi},
  doi      = {10.1016/j.eswa.2020.113788},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {3045704945},
  journal  = {Expert Systems With Applications},
  abstract = {Abstract   Epilepsy, a brain disease generally associated with seizures, has tremendous effects on people’s quality of life. Diagnosis of epileptic seizures is commonly performed on electroencephalography (EEG) signals, and by using computer-aided diagnosis systems (CADS), neurologists can diagnose epileptic seizure stages more accurately. In these systems, a mandatory stage is feature extraction, performed by handcrafting features or learning them, ordinarily by a deep neural net. While researches in this field commonly show the value of a group of limited features, yet an accurate comparison between different suggested features is essential. In this article, first, a comparison between the importance of 50 different handcrafted features for seizure detection is presented. Additionally, the computational complexity of features are investigated as well. Then the best features based on Fisher scores are picked to classify signals on a benchmark dataset for evaluation. Additionally, a convolutional autoencoder with five layers is applied to learn features in order to have a complete comparison among feature extraction approaches. Finally, a hybrid method is employed, which combines handcrafted features and encoding of autoencoder to reach high performance in seizure detection in EEG signals.}
}

@article{silver2018general,
  title     = {A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
  author    = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal   = {Science},
  volume    = {362},
  number    = {6419},
  pages     = {1140--1144},
  year      = {2018},
  publisher = {American Association for the Advancement of Science}
}

@article{song2023recent,
  title     = {Recent advances and future prospects for memristive materials, devices, and systems},
  author    = {Song, Min-Kyu and Kang, Ji-Hoon and Zhang, Xinyuan and Ji, Wonjae and Ascoli, Alon and Messaris, Ioannis and Demirkol, Ahmet Samil and Dong, Bowei and Aggarwal, Samarth and Wan, Weier and others},
  journal   = {ACS nano},
  volume    = {17},
  number    = {13},
  pages     = {11994--12039},
  year      = {2023},
  publisher = {American Chemical Society}
}

@article{Tan_2019,
  title    = {EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks},
  year     = {2019},
  author   = {Mingxing Tan and Quoc V. Le and Quoc V. Le and Quoc V. Le and Quoc V. Le and Quoc V. Le},
  doi      = {null},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {2946948417},
  journal  = {arXiv: Learning},
  abstract = {Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet. 
              To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.4% top-1 / 97.1% top-5 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet. Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7%), Flowers (98.8%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters. Source code is at this https URL.}
}

@article{tsukada2020neural,
  title     = {A neural network-based on-device learning anomaly detector for edge devices},
  author    = {Tsukada, Mineto and Kondo, Masaaki and Matsutani, Hiroki},
  journal   = {IEEE Transactions on Computers},
  volume    = {69},
  number    = {7},
  pages     = {1027--1044},
  year      = {2020},
  publisher = {IEEE}
}

@article{vaswani2017attention,
  title   = {Attention is all you need},
  author  = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal = {Advances in neural information processing systems},
  volume  = {30},
  year    = {2017}
}

@article{Wan_2022,
  title    = {A compute-in-memory chip based on resistive random-access memory},
  year     = {2022},
  author   = {Weier Wan and Rajkumar Kubendran and Clemens Schaefer and Sukru Burc Eryilmaz and Wenqiang Zhang and Dabin Wu and Stephen Deiss and Priyanka Raina and He Qian and Bin Gao and Siddharth Joshi and Huaqiang Wu and H.-S. Philip Wong and Gert Cauwenberghs},
  doi      = {10.1038/s41586-022-04992-8},
  pmid     = {35978128},
  pmcid    = {9385482},
  mag_id   = {4292121737},
  journal  = {Nature},
  abstract = {Abstract Realizing increasingly complex artificial intelligence (AI) functionalities directly on edge devices calls for unprecedented energy efficiency of edge hardware. Compute-in-memory (CIM) based on resistive random-access memory (RRAM) 1 promises to meet such demand by storing AI model weights in dense, analogue and non-volatile RRAM devices, and by performing AI computation directly within RRAM, thus eliminating power-hungry data movement between separate compute and memory 2–5 . Although recent studies have demonstrated in-memory matrix-vector multiplication on fully integrated RRAM-CIM hardware 6–17 , it remains a goal for a RRAM-CIM chip to simultaneously deliver high energy efficiency, versatility to support diverse models and software-comparable accuracy. Although efficiency, versatility and accuracy are all indispensable for broad adoption of the technology, the inter-related trade-offs among them cannot be addressed by isolated improvements on any single abstraction level of the design. Here, by co-optimizing across all hierarchies of the design from algorithms and architecture to circuits and devices, we present NeuRRAM—a RRAM-based CIM chip that simultaneously delivers versatility in reconfiguring CIM cores for diverse model architectures, energy efficiency that is two-times better than previous state-of-the-art RRAM-CIM chips across various computational bit-precisions, and inference accuracy comparable to software models quantized to four-bit weights across various AI tasks, including accuracy of 99.0 percent on MNIST 18 and 85.7 percent on CIFAR-10 19 image classification, 84.7-percent accuracy on Google speech command recognition 20 , and a 70-percent reduction in image-reconstruction error on a Bayesian image-recovery task.}
}

@inproceedings{wang2020always,
  title        = {Always-on, sub-300-nw, event-driven spiking neural network based on spike-driven clock-generation and clock-and power-gating for an ultra-low-power intelligent device},
  author       = {Wang, Dewei and Chundi, Pavan Kumar and Kim, Sung Justin and Yang, Minhao and Cerqueira, Joao Pedro and Kang, Joonsung and Jung, Seungchul and Kim, Sangjoon and Seok, Mingoo},
  booktitle    = {2020 IEEE Asian Solid-State Circuits Conference (A-SSCC)},
  pages        = {1--4},
  year         = {2020},
  organization = {IEEE}
}

@inproceedings{wang2021brief,
  title        = {Brief industry paper: Hdad: Hyperdimensional computing-based anomaly detection for automotive sensor attacks},
  author       = {Wang, Ruixuan and Kong, Fanxin and Sudler, Hasshi and Jiao, Xun},
  booktitle    = {2021 IEEE 27th Real-Time and Embedded Technology and Applications Symposium (RTAS)},
  pages        = {461--464},
  year         = {2021},
  organization = {IEEE}
}

@article{Wong_2012,
  title    = {Metal-Oxide RRAM},
  year     = {2012},
  author   = {Hon-Sum Philip Wong and Heng-Yuan Lee and Shimeng Yu and Yu-Sheng Chen and Yi Wu and Yi Wu and Pang-Shiu Chen and Pang-Shiu Chen and Byoungil Lee and Frederick T. Chen and Ming-Jinn Tsai},
  doi      = {10.1109/jproc.2012.2190369},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {2004823737},
  journal  = {Proceedings of the IEEE},
  abstract = {In this paper, recent progress of binary metal-oxide resistive switching random access memory (RRAM) is reviewed. The physical mechanism, material properties, and electrical characteristics of a variety of binary metal-oxide RRAM are discussed, with a focus on the use of RRAM for nonvolatile memory application. A review of recent development of large-scale RRAM arrays is given. Issues such as uniformity, endurance, retention, multibit operation, and scaling trends are discussed.}
}

@article{Xiao_2022,
  title    = {Memristive devices based hardware for unlabeled data processing},
  year     = {2022},
  author   = {Zhuojian Xiao and Bonan Yan and Teng Zhang and Ru Huang and Yuchao Yang and Yuchao Yang},
  doi      = {10.1088/2634-4386/ac734a},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {4281564948},
  journal  = {Neuromorphic computing and engineering},
  abstract = {Abstract Unlabeled data processing is of great significance for artificial intelligence (AI), since well-structured labelled data are scarce in a majority of practical applications due to the high cost of human annotation of labeling data. Therefore, automatous analysis of unlabeled datasets is important, and relevant algorithms for processing unlabeled data, such as k-means clustering, restricted Boltzmann machine and locally competitive algorithms etc., play a critical role in the development of AI techniques. Memristive devices offer potential for power and time efficient implementation of unlabeled data processing due to their unique properties in neuromorphic and in-memory computing. This review provides an overview of the design principles and applications of memristive devices for various unlabeled data processing and cognitive AI tasks.}
}

@article{Xue_2019,
  title    = {24.1 A 1Mb Multibit ReRAM Computing-In-Memory Macro with 14.6ns Parallel MAC Computing Time for CNN Based AI Edge Processors},
  year     = {2019},
  author   = {Cheng-Xin Xue and Wei-Hao Chen and Je-Syu Liu and Jia-Fang Li and Jiafang Li and Wei-Yu Lin and Wei-En Lin and Jing-Hong Wang and Wei-Chen Wei and Ting-Wei Chang and Tung-Cheng Chang and Tsung-Yuan Huang and Hui-Yao Kao and Shih-Ying Wei and Yen-Cheng Chiu and Chun-Ying Lee and Chung-Chuan Lo and Chung-Chuan Lo and Chung-Chuan Lo and Ya-Chin King and Chorng-Jung Lin and Ren-Shuo Liu and Chih-Cheng Hsieh and Kea-Tiong Tang and Meng-Fan Chang},
  doi      = {10.1109/isscc.2019.8662395},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {2921329602},
  journal  = {2019 IEEE International Solid- State Circuits Conference - (ISSCC)},
  abstract = {Embedded nonvolatile memory (NVM) and computing-in-memory (CIM) are significantly reducing the latency (t MAC ) and energy consumption (E MAC ) of multiply- and-accumulate (MAC) operations in artificial intelligence (AI) edge devices [1, 2]. Previous ReRAM CIM macros demonstrated MAC operations for lb-input, ternary- weighted, 3b-output CNNs [1] or lb-input, 8b-weighted, 1b-output fully-connected networks with limited accuracy [2]. To support higher-accuracy convolution neural network heavy applications NVM-CIM should support multibit inputs/weights and multi-bit output (MAC-OUT) for CNN operations. One way to achieve multibit weights is to use a multi-level ReRAM cell to store the weight. However, as shown in Fig. 24.1.1, multibit ReRAM CIM faces several challenges. (1) a tradeoff between area and speed for multibit input/weight/MAC-OUT MAC operations; (2) sense amplifier’s high input offset, large area, and high parasitic load on the read-path due to large BL currents (I BL ) from multibit MAC; (3) limited accuracy due to a small read/sensing margin (I SM ) across MAC-OUT or variation in cell resistance (particularly MLC cells). To overcome these challenges, this work proposes, (1) a serial-input non-weighted product (SINWP) structure to optimize the tradeoff between area, t MAC  and E MAC , (2) a down-scaling weighted current translator (DSWCT) and positive-negative current- subtractor (PN-ISUB) for short delay, a small offset and a compact read-path area; and (3) a triple-margin small-offset current-mode sense amplifier (TMCSA) to tolerate a small I SM . A fabricated 55nm 1Mb ReRAM-CIM macro is the first ReRAM CIM macro to support CNN operations using multibit input/weight MAC-OUT. This device achieves the shortest CIM-MAC-access time (t AC ) among existing ReRAM-CIMs (t MAC =14.6ns with 2b-input, 3b-weight with 4b-MAC-OUT) and the best peak E MAC  of 53.17 TOPS/W (in binary mode).}
}

@article{Xue_2020,
  title    = {A CMOS-integrated compute-in-memory macro based on resistive random-access memory for AI edge devices},
  year     = {2020},
  author   = {Cheng-Xin Xue and Yen-Cheng Chiu and Ta-Wei Liu and Tsung-Yuan Huang and Je-Syu Liu and Ting-Wei Chang and Hui-Yao Kao and Jing-Hong Wang and Shih-Ying Wei and Chun-Ying Lee and Sheng-Po Huang and Je-Min Hung and Shih-Hsih Teng and Wei-Chen Wei and Yi-Ren Chen and Tzu-Hsiang Hsu and Yen-Kai Chen and Yun-Chen Lo and Tai-Hsing Wen and Chung-Chuan Lo and Chung-Chuan Lo and Ren-Shuo Liu and Chih-Cheng Hsieh and Kea-Tiong Tang and Mon-Shu Ho and Chin-Yi Su and Chung-Cheng Chou and Chou Chung-Cheng and Yu-Der Chih and Meng-Fan Chang},
  doi      = {10.1038/s41928-020-00505-5},
  pmid     = {null},
  pmcid    = {null},
  mag_id   = {3112668161},
  journal  = {Nature Electronics},
  abstract = {The development of small, energy-efficient artificial intelligence edge devices is limited in conventional computing architectures by the need to transfer data between the processor and memory. Non-volatile compute-in-memory (nvCIM) architectures have the potential to overcome such issues, but the development of high-bit-precision configurations required for dot-product operations remains challenging. In particular, input–output parallelism and cell-area limitations, as well as signal margin degradation, computing latency in multibit analogue readout operations and manufacturing challenges, still need to be addressed. Here we report a 2Mb nvCIM macro (which combines memory cells and related peripheral circuitry) that is based on single-level cell resistive random-access memory devices and is fabricated in a 22nm complementary metal–oxide–semiconductor foundry process. Compared with previous nvCIM schemes, our macro can perform multibit dot-product operations with increased input–output parallelism, reduced cell-array area, improved accuracy, and reduced computing latency and energy consumption. The macro can, in particular, achieve latencies between 9.2 and 18.3ns, and energy efficiencies between 146.21 and 36.61 tera-operations per second per watt, for binary and multibit input–weight–output configurations, respectively. Commercial complementary metal–oxide–semiconductor and resistive random-access memory technologies can be used to create multibit compute-in-memory circuits capable of fast and energy-efficient inference for use in small artificial intelligence edge devices.}
}

@inproceedings{yan2019rram,
  title        = {RRAM-based spiking nonvolatile computing-in-memory processing engine with precision-configurable in situ nonlinear activation},
  author       = {Yan, Bonan and Yang, Qing and Chen, Wei-Hao and Chang, Kung-Tang and Su, Jian-Wei and Hsu, Chien-Hua and Li, Sih-Han and Lee, Heng-Yuan and Sheu, Shyh-Shyuan and Ho, Mon-Shu and others},
  booktitle    = {2019 Symposium on VLSI Technology},
  pages        = {T86--T87},
  year         = {2019},
  organization = {IEEE}
}

@article{yin2020xnor,
  title     = {XNOR-SRAM: In-memory computing SRAM macro for binary/ternary deep neural networks},
  author    = {Yin, Shihui and Jiang, Zhewei and Seo, Jae-Sun and Seok, Mingoo},
  journal   = {IEEE Journal of Solid-State Circuits},
  volume    = {55},
  number    = {6},
  pages     = {1733--1743},
  year      = {2020},
  publisher = {IEEE}
}

@inproceedings{zhu2018mixed,
  title        = {Mixed size crossbar based RRAM CNN accelerator with overlapped mapping method},
  author       = {Zhu, Zhenhua and Lin, Jilan and Cheng, Ming and Xia, Lixue and Sun, Hanbo and Chen, Xiaoming and Wang, Yu and Yang, Huazhong},
  booktitle    = {2018 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)},
  pages        = {1--8},
  year         = {2018},
  organization = {IEEE}
}

@inproceedings{zyuban1998energy,
  title     = {The energy complexity of register files},
  author    = {Zyuban, Victor and Kogge, Peter},
  booktitle = {Proceedings of the 1998 international symposium on Low power electronics and design},
  pages     = {305--310},
  year      = {1998}
}